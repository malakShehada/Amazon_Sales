{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c862628a",
   "metadata": {},
   "source": [
    "# Amazon Sales Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bce603",
   "metadata": {},
   "source": [
    "### importing needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4a914a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import date\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bc8394f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading dataset function\n",
    "def load_data(filepath):\n",
    "    \"\"\"Load the dataset from a csv file.\"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    print(f\"Data loaded successfully. Shape: {df.shape}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e7669ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning prices function\n",
    "def clean_price_columns(df):\n",
    "    \"\"\"Cleans and converts price and discount columns to numeric\"\"\"\n",
    "    df['actual_price'] = df['actual_price'].replace('[₹,]', '', regex=True).astype(float)\n",
    "    df['discounted_price'] = df['discounted_price'].replace('[₹,]', '', regex=True).astype(float)\n",
    "    df['discount_percentage'] = df['discount_percentage'].replace('[%,]', '', regex=True).astype(float)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60da200b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning ratings function\n",
    "def clean_rating_columns(df):\n",
    "    \"\"\"Cleans rating and rating_count columns\"\"\"\n",
    "    df['rating'] = pd.to_numeric(df['rating'], errors='coerce').fillna(0)\n",
    "    df['rating_count'] = (\n",
    "        df['rating_count']\n",
    "        .astype(str)\n",
    "        .str.replace(',', '', regex=False)\n",
    "        .replace('nan', '0')\n",
    "        .replace('', '0')\n",
    "        .astype('int'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa88ef44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split categories function\n",
    "def process_categories(df):\n",
    "    \"\"\"Splits and processes category hierarchies into multiple columns.\"\"\"\n",
    "    cat_lists = (\n",
    "        df['category']\n",
    "        .fillna('')\n",
    "        .astype(str)\n",
    "        .str.split('|')\n",
    "        .map(lambda xs: [x.strip() for x in xs if x.strip() != ''])\n",
    "    )\n",
    "    max_depth = cat_lists.map(len).max()\n",
    "    cols = [f'cat_l{i+1}' for i in range(max_depth)]\n",
    "    category_df = pd.DataFrame(cat_lists.tolist(), index=df.index, columns=cols)\n",
    "    df = pd.concat([df, category_df], axis=1)\n",
    "    \n",
    "    def get_last_category(row):\n",
    "        for c in reversed(cols):\n",
    "            if pd.notna(row.get(c)) and str(row[c]).strip() != '':\n",
    "                return row[c]\n",
    "        return None\n",
    "    \n",
    "    df['cat_leaf'] = df[cols].apply(get_last_category, axis=1)\n",
    "    df['cat_depth'] = df[cols].notna().sum(axis=1)\n",
    "    df['category_path'] = df[cols].apply(\n",
    "        lambda r: '|'.join([str(r[c]) for c in cols if pd.notna(r[c])]), axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bea93a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quality checks function\n",
    "def run_quality_checks(df):\n",
    "    \n",
    "    #prepare category data\n",
    "    level_cols = [c for c in df.columns if c.startswith('cat_l')]\n",
    "    \n",
    "    # Fix None issue and recalculate (this was outside the function before)\n",
    "    df[level_cols] = df[level_cols].replace({None: pd.NA})\n",
    "    calc_depth = df[level_cols].notna().sum(axis=1)\n",
    "    df['cat_depth'] = calc_depth\n",
    "    \n",
    "    # Recalculate path\n",
    "    df['category_path'] = df[level_cols].apply(\n",
    "        lambda r: \"|\".join([str(r[c]) for c in level_cols if pd.notna(r[c])]),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    \"\"\"Runs data quality assertions on the DataFrame.\"\"\"\n",
    "    # discount_price has to be <= actual_price\n",
    "    assert (df['discounted_price'] <= df['actual_price']).all(), \\\n",
    "    \"Found Products where discounted_price > actual_price\"\n",
    "\n",
    "    # rating has to be between 0 & 5\n",
    "    assert df['rating'].between(0, 5, inclusive = 'both').all(), \\\n",
    "    \"Found invalid values in 'rating' column (should be 0-5)\"\n",
    "\n",
    "    # each level has to have a parent\n",
    "    for i in range(1,7):\n",
    "        parent = f'cat_l{i}'\n",
    "        child = f'cat_l{i+1}'\n",
    "        assert not (df[child].notna() & df[parent].isna()).any(), \\\n",
    "        f\"Found rows where {child} exists without {parent}\"\n",
    "    \n",
    "    # depth check\n",
    "    assert (calc_depth == df['cat_depth']).all(), \"Depth mismatch\"\n",
    "    # path check\n",
    "    assert ((df['category_path'].str.count(r'\\|').fillna(0).astype(int) + 1) \n",
    "            == df['cat_depth']).all(), \"Path mismatch with depth\"\n",
    "    print(\"All quality checks passed ✅\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3367172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deduplicate function\n",
    "def deduplicate_products(df):\n",
    "    \"\"\"Removes duplicate product_id rows keeping the one with highest rating count and rating.\"\"\"\n",
    "    df = (df.sort_values(['product_id', 'rating_count', 'rating'], ascending=[True, False, False])\n",
    "          .drop_duplicates('product_id', keep='first'))\n",
    "    assert not df['product_id'].duplicated().any(), \"Duplicates remain!\"\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06f01efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Tables to Load them on Database\n",
    "# build dim_category table function\n",
    "def build_dim_category(df):\n",
    "    level_cols = [c for c in df.columns if c.startswith('cat_l')]\n",
    "    dim_category = (df[['category_path', 'cat_leaf', 'cat_depth'] + level_cols]\n",
    "                    .drop_duplicates('category_path')\n",
    "                    .reset_index(drop=True))\n",
    "    dim_category['category_key'] = range(1, len(dim_category) + 1)\n",
    "    return dim_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff8dc3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build dim_product table function\n",
    "def build_dim_product(df):\n",
    "    columns = ['product_id', 'product_name', 'img_link', 'product_link', 'cat_leaf']\n",
    "    dim_product = df[columns].copy()\n",
    "    return dim_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae63d160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build bridge_product_category table function\n",
    "def build_bridge_product_category(df, dim_category):\n",
    "    bridge = (df[['product_id', 'category_path']]\n",
    "              .merge(dim_category[['category_path', 'category_key']],\n",
    "                     on='category_path', how='left'))\n",
    "    return bridge[['product_id', 'category_key']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9cc828c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build fact_product_snapshot table function\n",
    "def build_fact_product_snapshot(df, bridge):\n",
    "    fact = df[['product_id', 'discounted_price', 'actual_price', 'discount_percentage', 'rating', 'rating_count']].copy()\n",
    "    fact = fact.merge(bridge, on='product_id', how='left')\n",
    "    fact['ingestion_date'] = date.today()\n",
    "    return fact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37c666ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully. Shape: (1465, 16)\n",
      "All quality checks passed ✅\n",
      "\\n=== Dim Category ===\n",
      "                                       category_path               cat_leaf  \\\n",
      "0  Computers&Accessories|NetworkingDevices|Networ...    WirelessUSBAdapters   \n",
      "1  Electronics|GeneralPurposeBatteries&BatteryCha...  RechargeableBatteries   \n",
      "2  Computers&Accessories|Accessories&Peripherals|...                   Mice   \n",
      "3  Computers&Accessories|ExternalDevices&DataStor...              PenDrives   \n",
      "4  Electronics|HomeTheater,TV&Video|Accessories|C...          OpticalCables   \n",
      "\n",
      "   cat_depth                 cat_l1                                   cat_l2  \\\n",
      "0          5  Computers&Accessories                        NetworkingDevices   \n",
      "1          4            Electronics  GeneralPurposeBatteries&BatteryChargers   \n",
      "2          5  Computers&Accessories                  Accessories&Peripherals   \n",
      "3          4  Computers&Accessories              ExternalDevices&DataStorage   \n",
      "4          6            Electronics                     HomeTheater,TV&Video   \n",
      "\n",
      "                        cat_l3               cat_l4         cat_l5 cat_l6  \\\n",
      "0              NetworkAdapters  WirelessUSBAdapters           <NA>   <NA>   \n",
      "1        RechargeableBatteries                 <NA>           <NA>   <NA>   \n",
      "2  Keyboards,Mice&InputDevices                 Mice           <NA>   <NA>   \n",
      "3                    PenDrives                 <NA>           <NA>   <NA>   \n",
      "4                  Accessories               Cables  OpticalCables   <NA>   \n",
      "\n",
      "  cat_l7               cat_leaf  category_key  \n",
      "0   <NA>    WirelessUSBAdapters             1  \n",
      "1   <NA>  RechargeableBatteries             2  \n",
      "2   <NA>                   Mice             3  \n",
      "3   <NA>              PenDrives             4  \n",
      "4   <NA>          OpticalCables             5  \n",
      "Shape: (211, 12)\n",
      "\\n=== Dim Product ===\n",
      "     product_id                                       product_name  \\\n",
      "46   B002PD61Y4  D-Link DWA-131 300 Mbps Wireless Nano USB Adap...   \n",
      "143  B002SZEOLG  TP-Link Nano USB WiFi Dongle 150Mbps High Gain...   \n",
      "721  B003B00484  Duracell Plus AAA Rechargeable Batteries (750 ...   \n",
      "724  B003L62T7W  Logitech B100 Wired USB Mouse, 3 yr Warranty, ...   \n",
      "734  B004IO5BMQ  Logitech M235 Wireless Mouse, 1000 DPI Optical...   \n",
      "\n",
      "                                              img_link  \\\n",
      "46   https://m.media-amazon.com/images/I/31+NwZ8gb1...   \n",
      "143  https://m.media-amazon.com/images/I/31Wb+A3VVd...   \n",
      "721  https://m.media-amazon.com/images/I/418YrbHVLC...   \n",
      "724  https://m.media-amazon.com/images/I/31iFF1Kbkp...   \n",
      "734  https://m.media-amazon.com/images/I/31CtVvtFt+...   \n",
      "\n",
      "                                          product_link               cat_leaf  \n",
      "46   https://www.amazon.in/D-Link-DWA-131-Wireless-...    WirelessUSBAdapters  \n",
      "143  https://www.amazon.in/TP-Link-TL-WN722N-150Mbp...    WirelessUSBAdapters  \n",
      "721  https://www.amazon.in/Duracell-AAA-750mAh-Rech...  RechargeableBatteries  \n",
      "724  https://www.amazon.in/Logitech-B100-Optical-Mo...                   Mice  \n",
      "734  https://www.amazon.in/Logitech-M235-Wireless-M...                   Mice  \n",
      "Shape: (1351, 5)\n",
      "\\n=== Bridge Table ===\n",
      "   product_id  category_key\n",
      "0  B002PD61Y4             1\n",
      "1  B002SZEOLG             1\n",
      "2  B003B00484             2\n",
      "3  B003L62T7W             3\n",
      "4  B004IO5BMQ             3\n",
      "Shape: (1351, 2)\n",
      "\\n=== Fact Snapshot ===\n",
      "   product_id  discounted_price  actual_price  discount_percentage  rating  \\\n",
      "0  B002PD61Y4             507.0        1208.0                 58.0     4.1   \n",
      "1  B002SZEOLG             749.0        1339.0                 44.0     4.2   \n",
      "2  B003B00484             399.0         499.0                 20.0     4.3   \n",
      "3  B003L62T7W             279.0         375.0                 26.0     4.3   \n",
      "4  B004IO5BMQ             699.0         995.0                 30.0     4.5   \n",
      "\n",
      "   rating_count  category_key ingestion_date  \n",
      "0          8131             1     2025-11-20  \n",
      "1        179692             1     2025-11-20  \n",
      "2         27201             2     2025-11-20  \n",
      "3         31534             3     2025-11-20  \n",
      "4         54405             3     2025-11-20  \n",
      "Shape: (1351, 8)\n",
      "\\n✅ All tables saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# main function\n",
    "def main():\n",
    "    filepath = \"amazon.csv\"\n",
    "    \n",
    "    # load and clean the data\n",
    "    sales_data = load_data(filepath)\n",
    "    sales_data = clean_price_columns(sales_data)\n",
    "    sales_data = clean_rating_columns(sales_data)\n",
    "    sales_data = process_categories(sales_data)\n",
    "    \n",
    "    # cheack the quality and remove duplicates\n",
    "    sales_data = run_quality_checks(sales_data)\n",
    "    sales_data = deduplicate_products(sales_data)\n",
    "    \n",
    "    # build new tables\n",
    "    dim_category = build_dim_category(sales_data)\n",
    "    dim_product = build_dim_product(sales_data)\n",
    "    bridge = build_bridge_product_category(sales_data, dim_category)\n",
    "    fact_snapshot = build_fact_product_snapshot(sales_data, bridge)\n",
    "    \n",
    "    # print new tables head\n",
    "    print(\"\\\\n=== Dim Category ===\")\n",
    "    print(dim_category.head())\n",
    "    print(f\"Shape: {dim_category.shape}\")\n",
    "    \n",
    "    print(\"\\\\n=== Dim Product ===\")\n",
    "    print(dim_product.head())\n",
    "    print(f\"Shape: {dim_product.shape}\")\n",
    "    \n",
    "    print(\"\\\\n=== Bridge Table ===\")\n",
    "    print(bridge.head())\n",
    "    print(f\"Shape: {bridge.shape}\")\n",
    "    \n",
    "    print(\"\\\\n=== Fact Snapshot ===\")\n",
    "    print(fact_snapshot.head())\n",
    "    print(f\"Shape: {fact_snapshot.shape}\")\n",
    "    \n",
    "    # save new tables\n",
    "    dim_product.to_csv('dim_product.csv', index=False)\n",
    "    dim_category.to_csv('dim_category.csv', index=False)\n",
    "    fact_snapshot.to_csv('fact_product_snapshot.csv', index=False)\n",
    "    bridge.to_csv('bridge_product_category.csv', index=False)\n",
    "    \n",
    "    print(\"\\\\n✅ All tables saved successfully!\")\n",
    "    \n",
    "    return sales_data, dim_category, dim_product, bridge, fact_snapshot\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sales_data, dim_category, dim_product, bridge, fact_snapshot = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d4e60d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
